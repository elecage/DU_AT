#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
# ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ Xorg ì“¸ ë•Œ ì°½ì´ ì•ˆ ëœ¨ëŠ” ë¬¸ì œ ë°©ì§€ (Waylandì—ì„œë„ xcbë¡œ ê°•ì œ)
os.environ["QT_QPA_PLATFORM"] = "xcb"

import argparse
import threading
import time
import json
import sys
import socket
import signal
import numpy as np
import paho.mqtt.client as mqtt
import cv2
from flask import Flask, Response  # ğŸ”¥ MJPEG ìŠ¤íŠ¸ë¦¬ë°ìš©

from hailo_platform import (
    VDevice, HEF, InferVStreams,
    InputVStreamParams, OutputVStreamParams,
    HailoStreamInterface, ConfigureParams,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸€ë¡œë²Œ ì¢…ë£Œ ì´ë²¤íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ì•ˆì „ ì¢…ë£Œìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stop_event = threading.Event()

def _request_shutdown(reason=""):
    print(f"ğŸ›‘ ì¢…ë£Œ ìš”ì²­: {reason}")
    stop_event.set()

def _setup_signal_handlers():
    def _handler(sig, frame):
        _request_shutdown(f"signal={sig}")
    signal.signal(signal.SIGINT, _handler)   # Ctrl+C
    signal.signal(signal.SIGTERM, _handler)  # systemd stop ë“±

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MJPEG ìŠ¤íŠ¸ë¦¬ë°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = Flask(__name__)
latest_jpeg = None  # ê°€ì¥ ìµœê·¼ í”„ë ˆì„ì„ JPEGë¡œ ì €ì¥í•´ë‘”ë‹¤ (ë°”ì´íŠ¸)

def mjpeg_generator():
    """
    ìµœì‹  í”„ë ˆì„ì„ multipart/x-mixed-replace í˜•íƒœë¡œ ê³„ì† ë‚´ë³´ë‚´ëŠ” ì œë„ˆë ˆì´í„°
    """
    global latest_jpeg
    boundary = b"--frame\r\n"
    while not stop_event.is_set():
        if latest_jpeg is not None:
            yield (
                boundary +
                b"Content-Type: image/jpeg\r\n\r\n" +
                latest_jpeg +
                b"\r\n"
            )
        else:
            time.sleep(0.05)

@app.route("/video")
def video_feed():
    """
    ë¸Œë¼ìš°ì €ì—ì„œ http://<host>:<port>/video ë¡œ ì ‘ì†í•˜ë©´
    M-JPEG ìŠ¤íŠ¸ë¦¼ì„ ë³¼ ìˆ˜ ìˆìŒ
    """
    return Response(
        mjpeg_generator(),
        mimetype="multipart/x-mixed-replace; boundary=frame"
    )

def start_mjpeg_server(host="0.0.0.0", port=5055):
    """
    Flask ì•±ì„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ë„ì›Œì„œ /video ìŠ¤íŠ¸ë¦¼ ì œê³µ
    """
    th = threading.Thread(
        target=lambda: app.run(host=host, port=port, threaded=True, use_reloader=False),
        daemon=True
    )
    th.start()
    print(f"ğŸŒ MJPEG ì„œë²„ ì‹œì‘: http://{host}:{port}/video")
    return th


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MQTT ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MQTT_BROKER = "192.168.0.24"
MQTT_PORT = 1883
TEMP_TOPIC = "system/temperature/pi5"
TEMP_CLIENT_ID = f"raspi_temp_{socket.gethostname()}"

MQTT_CONFIG = {
    "smoke": {
        "topic": "AI_smoke_alert",
        "payload": {"sensor_id": "AI_D_smoke", "event": "smoke_detected"}
    },
    "fire": {
        "topic": "AI_fire_alert",
        "payload": {"sensor_id": "AI_D_fire", "event": "fire_detected"}
    }
}

last_sent = {"fire": 0, "smoke": 0}
COOLDOWN = 20  # ì´ˆ ë‹¨ìœ„ë¡œ ì•Œë¦¼ ì¿¨ë‹¤ìš´


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MQTT ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def try_connect(client_id=None):
    """MQTT ë¸Œë¡œì»¤ì— ì—°ê²° ì‹œë„í•˜ê³  client (ë˜ëŠ” None) ë¦¬í„´."""
    try:
        client = mqtt.Client(
            client_id=client_id or f"ai_fire_{socket.gethostname()}_{os.getpid()}",
            protocol=mqtt.MQTTv311,
            callback_api_version=mqtt.CallbackAPIVersion.VERSION2
        )
        client.connect(MQTT_BROKER, MQTT_PORT, keepalive=15)
        client.loop_start()
        print(f"âœ… MQTT ì—°ê²° ì„±ê³µ (client_id={client._client_id.decode()})")
        return client
    except Exception as e:
        print(f"âš ï¸ MQTT ì—°ê²° ì‹¤íŒ¨ (client_id={client_id}):", e)
        return None


def get_cpu_temp():
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ CPU ì˜¨ë„(Â°C). ì—†ëŠ” í™˜ê²½ì´ë©´ 0 ë¦¬í„´."""
    try:
        with open("/sys/class/thermal/thermal_zone0/temp", "r") as f:
            return float(f.read()) / 1000.0
    except FileNotFoundError:
        print("âš ï¸ CPU ì˜¨ë„ ì„¼ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0 ì‚¬ìš©.")
        return 0.0


def cpu_temp_publisher():
    """
    ë°±ê·¸ë¼ìš´ë“œë¡œ ëŒì•„ê°€ë©´ì„œ CPU ì˜¨ë„ ì£¼ê¸°ì ìœ¼ë¡œ MQTT publish.
    ì—°ê²° ëŠê¸°ë©´ 10ì´ˆë§ˆë‹¤ ì¬ì‹œë„.
    stop_event ì„¸íŠ¸ë˜ë©´ ì•ˆì „ ì¢…ë£Œ.
    """
    client = try_connect(TEMP_CLIENT_ID)
    reconnect_timer = time.time()
    try:
        while not stop_event.is_set():
            try:
                if client is None and time.time() - reconnect_timer > 10:
                    client = try_connect(TEMP_CLIENT_ID)
                    reconnect_timer = time.time()

                payload = {
                    "sensor_id": "raspi_temp_pi5",
                    "value": get_cpu_temp(),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                }

                if client:
                    try:
                        client.publish(TEMP_TOPIC, json.dumps(payload), qos=0)
                        print("ğŸ“¤ ì˜¨ë„ ì „ì†¡:", payload)
                    except Exception as e:
                        print("âš ï¸ ì˜¨ë„ MQTT ì „ì†¡ ì‹¤íŒ¨:", e)
                        client = None
                else:
                    print("âš ï¸ ì˜¨ë„ MQTT ë¯¸ì—°ê²° ìƒíƒœ, ë°ì´í„° ì „ì†¡ ìƒëµ")

                # ì§§ê²Œ ë‚˜ëˆ ì„œ sleep â†’ ì¢…ë£Œ ì‹ í˜¸ ë°˜ì‘ì„± í–¥ìƒ
                for _ in range(30):
                    if stop_event.is_set():
                        break
                    time.sleep(1)

            except Exception as e:
                print("âš ï¸ CPU ì˜¨ë„ ë£¨í”„ ì˜¤ë¥˜:", e)
                for _ in range(30):
                    if stop_event.is_set():
                        break
                    time.sleep(1)
    finally:
        if client:
            try:
                client.loop_stop()
                client.disconnect()
            except Exception:
                pass
        print("âœ… ì˜¨ë„ í¼ë¸”ë¦¬ì…” ì¢…ë£Œ")


def send_detection_mqtt(client, cls_name):
    """
    fire/smoke ê°ì§€ ì‹œ MQTT ì•Œë¦¼ ì „ì†¡ (ì¿¨ë‹¤ìš´ ì ìš©)
    """
    global last_sent
    if client is None:
        return None

    now = time.time()
    if now - last_sent.get(cls_name, 0) < COOLDOWN:
        print(f"â³ {cls_name} MQTT ì¿¨ë‹¤ìš´ ì¤‘, ì „ì†¡ ìƒëµ")
        return client

    cfg = MQTT_CONFIG.get(cls_name)
    if cfg:
        try:
            client.publish(cfg["topic"], json.dumps(cfg["payload"]), qos=0)
            last_sent[cls_name] = now
            print(f"ğŸ“¤ MQTT ì „ì†¡ â†’ topic: {cfg['topic']}, payload: {cfg['payload']}")
        except Exception as e:
            print(f"âš ï¸ MQTT ì „ì†¡ ì‹¤íŒ¨ ({cls_name}):", e)
            return None
    else:
        print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤ '{cls_name}'")
    return client


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¹´ë©”ë¼ ì—´ê¸°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def open_capture(args):
    """
    args.api:    auto|v4l2|gst
    args.fourcc: MJPG|YUYV|NONE
    args.cap_width/height: ì›í•˜ëŠ” í•´ìƒë„
    """
    if args.api == "gst":
        # GStreamer íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—´ê¸°
        dev = f"/dev/video{args.camera_index}"
        w, h = args.cap_width, args.cap_height

        if args.fourcc == "MJPG":
            pipe = (
                f"v4l2src device={dev} ! "
                f"image/jpeg,framerate=30/1,width={w},height={h} ! "
                f"jpegdec ! videoconvert ! video/x-raw,format=BGR ! "
                f"appsink drop=true"
            )
        elif args.fourcc == "YUYV":
            pipe = (
                f"v4l2src device={dev} io-mode=2 ! "
                f"video/x-raw,format=YUY2,framerate=30/1,width={w},height={h} ! "
                f"videoconvert ! video/x-raw,format=BGR ! "
                f"appsink drop=true"
            )
        else:
            pipe = (
                f"v4l2src device={dev} ! "
                f"videoconvert ! video/x-raw,format=BGR ! "
                f"appsink drop=true"
            )

        cap = cv2.VideoCapture(pipe, cv2.CAP_GSTREAMER)
        return cap

    # ì¼ë°˜ V4L2 ê²½ë¡œ
    api_flag = cv2.CAP_V4L2 if args.api in ("auto", "v4l2") else cv2.CAP_ANY
    cap = cv2.VideoCapture(args.camera_index, api_flag)

    # fourcc ì„¤ì • (ì˜ˆ: MJPG)
    if args.fourcc != "NONE":
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*args.fourcc))

    # í•´ìƒë„ íŒíŠ¸
    if args.cap_width > 0 and args.cap_height > 0:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, args.cap_width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, args.cap_height)

    return cap


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²˜ë¦¬ (ëª¨ë¸ ì…ë ¥ ë§Œë“¤ê¸°) + ë³µì› ë§¤í•‘ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_for_hailo(frame_bgr, net_h=640, net_w=640):
    """
    net_h x net_w RGB uint8 ì¤€ë¹„:
    - BGR -> RGB
    - ì§§ì€ ë³€ì„ ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
    - ì¤‘ì•™ í¬ë¡­
    - uint8 ìœ ì§€
    """
    h0, w0 = frame_bgr.shape[:2]

    # BGR -> RGB
    rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)

    # ìŠ¤ì¼€ì¼ ê²°ì • (ì§§ì€ ë³€ì„ netì— ë§ì¶˜ë‹¤)
    if h0 < w0:
        scale = net_h / float(h0)
        new_h, new_w = net_h, int(round(w0 * scale))
    else:
        scale = net_w / float(w0)
        new_w, new_h = net_w, int(round(h0 * scale))

    resized = cv2.resize(rgb, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

    # ì¤‘ì•™ í¬ë¡­
    left = max(0, (new_w - net_w) // 2)
    top = max(0, (new_h - net_h) // 2)
    right = left + net_w
    bottom = top + net_h
    crop = resized[top:bottom, left:right, :]

    # í¬ë¡­ëœ ê²Œ ë¶€ì¡±í•˜ë©´ íŒ¨ë”©
    if crop.shape[0] != net_h or crop.shape[1] != net_w:
        canvas = np.zeros((net_h, net_w, 3), dtype=np.uint8)
        y_off = (net_h - crop.shape[0]) // 2
        x_off = (net_w - crop.shape[1]) // 2
        canvas[y_off:y_off+crop.shape[0], x_off:x_off+crop.shape[1], :] = crop
        crop = canvas

    crop = np.ascontiguousarray(crop.astype(np.uint8))
    return crop, scale, left, top


def map_box_back_to_original(x1, y1, x2, y2, scale, left, top, orig_w, orig_h):
    """
    ëª¨ë¸ ì¢Œí‘œ(640x640 crop ê¸°ì¤€) ë°•ìŠ¤ë¥¼ ì›ë³¸ frame ì¢Œí‘œë¡œ ë˜ëŒë¦°ë‹¤.
    """
    x1o = (x1 + left) / scale
    y1o = (y1 + top) / scale
    x2o = (x2 + left) / scale
    y2o = (y2 + top) / scale

    # í™”ë©´ ë°– ë„˜ì–´ê°€ëŠ” ê°’ í´ë¨í”„
    x1o = max(0, min(orig_w - 1, x1o))
    y1o = max(0, min(orig_h - 1, y1o))
    x2o = max(0, min(orig_w - 1, x2o))
    y2o = max(0, min(orig_h - 1, y2o))

    return int(x1o), int(y1o), int(x2o), int(y2o)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í›„ì²˜ë¦¬: DFL decode + NMS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _sigmoid(x):
    return 1.0 / (1.0 + np.exp(-x))

def _softmax(x, axis=-1):
    x = x - np.max(x, axis=axis, keepdims=True)
    e = np.exp(x)
    return e / np.sum(e, axis=axis, keepdims=True)

def _squeeze_hw(arr):
    """
    InferVStreams ê²°ê³¼ (1,H,W,C) â†’ (H,W,C) ë¡œ batch ì°¨ì› ì œê±°
    """
    if arr is None:
        return None
    a = np.asarray(arr)
    while a.ndim > 3 and a.shape[0] == 1:
        a = a[0]
    return a

def decode_head_dfl(reg_map, cls_map, stride, num_bins=16, score_thr=0.5):
    """
    DFL ê¸°ë°˜ íšŒê·€ ê²°ê³¼ë¥¼ bboxë¡œ ë³µì›
    """
    if reg_map is None or cls_map is None:
        return (np.zeros((0, 4), dtype=np.float32),
                np.zeros((0,), dtype=np.float32))

    Hs, Ws, C = reg_map.shape
    expected_c = 4 * num_bins
    if C != expected_c:
        print(f"âš ï¸ ì˜ˆê¸°ì¹˜ ì•Šì€ reg_map ì±„ë„ìˆ˜ {C}, ê¸°ëŒ€ {expected_c}")
        return (np.zeros((0, 4), dtype=np.float32),
                np.zeros((0,), dtype=np.float32))

    # class score (sigmoid)
    cls_score = _sigmoid(cls_map[..., 0])  # (Hs,Ws)

    # DFL ë¶„í¬ -> ê¸°ëŒ€ê°’
    reg4 = reg_map.reshape(Hs, Ws, 4, num_bins)
    prob = _softmax(reg4, axis=3)  # (Hs,Ws,4,num_bins)
    bins = np.arange(num_bins, dtype=np.float32)
    dist = np.sum(prob * bins[None, None, None, :], axis=3)  # (Hs,Ws,4)

    l = dist[..., 0]
    t = dist[..., 1]
    r = dist[..., 2]
    b = dist[..., 3]

    # grid ì¢Œí‘œ (ì…€ ì„¼í„° â†’ stride ë°˜ì˜)
    gy, gx = np.meshgrid(
        np.arange(Hs, dtype=np.float32),
        np.arange(Ws, dtype=np.float32),
        indexing='ij'
    )
    cx = (gx + 0.5) * stride
    cy = (gy + 0.5) * stride

    # box ë³µì› xyxy
    x1 = cx - l * stride
    y1 = cy - t * stride
    x2 = cx + r * stride
    y2 = cy + b * stride

    # flatten
    x1 = x1.reshape(-1)
    y1 = y1.reshape(-1)
    x2 = x2.reshape(-1)
    y2 = y2.reshape(-1)
    sc = cls_score.reshape(-1)

    # confidence í•„í„°
    keep = sc >= float(score_thr)
    if not np.any(keep):
        return (np.zeros((0, 4), dtype=np.float32),
                np.zeros((0,), dtype=np.float32))

    boxes = np.stack([x1[keep], y1[keep], x2[keep], y2[keep]], axis=1).astype(np.float32)
    scores = sc[keep].astype(np.float32)
    return boxes, scores

def nms_numpy(boxes, scores, iou_th=0.5, max_dets=100):
    """
    ê°„ë‹¨í•œ greedy NMS.
    """
    if boxes.shape[0] == 0:
        return []

    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]

    areas = (x2 - x1) * (y2 - y1)
    order = np.argsort(-scores)  # high -> low

    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        if len(keep) >= max_dets:
            break

        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)

        inds = np.where(iou <= iou_th)[0]
        order = order[inds + 1]

    return keep

def resolve_decoder_layers_from_cfg(decoders_cfg, out_vstream_names):
    """
    cfgì— ì íŒ í—¤ë“œ ë ˆì´ì–´ ì´ë¦„(prefix ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)ì„
    ì‹¤ì œ HEF ì¶œë ¥ vstream ì´ë¦„ìœ¼ë¡œ suffix ê¸°ì¤€ ë§¤í•‘
    """
    suffix_map = {}
    for full in out_vstream_names:
        suf = full.split("/")[-1]
        suffix_map[suf] = full

    resolved = []
    for d in decoders_cfg:
        stride = d["stride"]
        reg_suffix = d["reg_layer"].split("/")[-1]
        cls_suffix = d["cls_layer"].split("/")[-1]

        reg_full = suffix_map.get(reg_suffix, d["reg_layer"])
        cls_full = suffix_map.get(cls_suffix, d["cls_layer"])

        resolved.append({
            "stride": stride,
            "reg_layer": reg_full,
            "cls_layer": cls_full
        })
    return resolved

def postprocess_all_scales(results_dict,
                           decoders_resolved,
                           num_bins,
                           score_thr,
                           iou_th,
                           max_det):
    """
    ì—¬ëŸ¬ ìŠ¤ì¼€ì¼ í—¤ë“œë“¤ì—ì„œ ë‚˜ì˜¨ bbox í›„ë³´ë“¤ì„ í•©ì¹˜ê³  NMS ì ìš©
    return dets (N,6): [x1,y1,x2,y2,score,cls_id]
    """
    all_boxes = []
    all_scores = []

    for d in decoders_resolved:
        stride = d["stride"]
        reg_name = d["reg_layer"]
        cls_name = d["cls_layer"]

        reg_map = _squeeze_hw(results_dict.get(reg_name))
        cls_map = _squeeze_hw(results_dict.get(cls_name))

        boxes, scores = decode_head_dfl(
            reg_map,
            cls_map,
            stride=stride,
            num_bins=num_bins,
            score_thr=score_thr
        )

        if boxes.shape[0] > 0:
            all_boxes.append(boxes)
            all_scores.append(scores)

    if not all_boxes:
        return np.zeros((0, 6), dtype=np.float32)

    all_boxes = np.concatenate(all_boxes, axis=0)
    all_scores = np.concatenate(all_scores, axis=0)

    keep_idx = nms_numpy(all_boxes, all_scores, iou_th=iou_th, max_dets=max_det)
    if not keep_idx:
        return np.zeros((0, 6), dtype=np.float32)

    final_boxes = all_boxes[keep_idx]
    final_scores = all_scores[keep_idx]

    # ë‹¨ì¼ í´ë˜ìŠ¤ ê°€ì • â†’ cls_id = 0
    cls_col = np.zeros((final_boxes.shape[0], 1), dtype=np.float32)

    dets = np.concatenate(
        [
            final_boxes.astype(np.float32),
            final_scores.reshape(-1, 1).astype(np.float32),
            cls_col
        ],
        axis=1
    )
    return dets


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(args):
    global latest_jpeg

    # ë¼ë²¨ ë¡œë”© (labels.json â†’ {"labels": ["fire","smoke", ...]})
    labels = None
    try:
        with open(args.labels_path) as f:
            labels = json.load(f).get("labels", None)
    except Exception:
        labels = None

    # NMS/decoder config ë¡œë”©
    with open(args.config_path, "r") as f:
        nms_cfg = json.load(f)

    cfg_num_bins = int(nms_cfg.get("regression_length", 16))
    cfg_score_thr = float(nms_cfg.get("nms_scores_th", 0.5))
    cfg_iou_thr = float(nms_cfg.get("nms_iou_th", 0.5))
    cfg_max_det = int(nms_cfg.get("max_proposals_per_class", 100))
    cfg_decoders = nms_cfg.get("bbox_decoders", [])

    # ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ë®ì–´ì“°ê¸° ê°€ëŠ¥
    score_thr = args.score_thr if args.score_thr is not None else cfg_score_thr
    iou_thr = args.iou_thr if args.iou_thr is not None else cfg_iou_thr
    max_det = args.max_det if args.max_det is not None else cfg_max_det

    # MQTT ìŠ¤íƒ€íŠ¸
    mqtt_client = try_connect()
    temp_thread = threading.Thread(target=cpu_temp_publisher, daemon=True)
    temp_thread.start()

    # Hailo ì¥ì¹˜/ë„¤íŠ¸ì›Œí¬ ì¤€ë¹„
    with VDevice() as device:
        hef = HEF(args.hef_path)

        cfg_params = ConfigureParams.create_from_hef(
            hef,
            interface=HailoStreamInterface.PCIe
        )
        ng_list = device.configure(hef, cfg_params)
        network_group = ng_list[0] if isinstance(ng_list, (list, tuple)) else ng_list

        # vstream ì •ë³´
        in_infos = hef.get_input_vstream_infos()
        out_infos = hef.get_output_vstream_infos()
        assert len(in_infos) >= 1, "ì…ë ¥ vstream ì—†ìŒ?"
        assert len(out_infos) >= 1, "ì¶œë ¥ vstream ì—†ìŒ?"

        in_info = in_infos[0]
        in_shape = tuple(in_info.shape)  # (H,W,3) NHWC
        assert len(in_shape) == 3 and in_shape[2] == 3, f"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì…ë ¥ shape: {in_shape}"
        net_h, net_w = int(in_shape[0]), int(in_shape[1])

        print("ğŸ” ì…ë ¥ vstream ëª©ë¡:")
        for ii in in_infos:
            print(f"   - {ii.name} : shape={ii.shape}")
        print("ğŸ” ì¶œë ¥ vstream ëª©ë¡:")
        for oi in out_infos:
            print(f"   - {oi.name} : shape={oi.shape}")

        print(f"ğŸ“‹ HEF ì…ë ¥: shape={in_shape}, layout=NHWC, size={net_w}x{net_h}")

        # decoder layer suffix ë§¤í•‘
        out_names = [oi.name for oi in out_infos]
        decoders_resolved = resolve_decoder_layers_from_cfg(cfg_decoders, out_names)

        # vstream params (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
        in_params  = InputVStreamParams.make_from_network_group(network_group)
        out_params = OutputVStreamParams.make_from_network_group(network_group)

        ng_params = network_group.create_params()

        with network_group.activate(ng_params):
            with InferVStreams(network_group, in_params, out_params) as infer_pipeline:
                in_name = in_info.name
                print(f"ğŸ” ì‚¬ìš© ì¤‘ì¸ ì…ë ¥ vstream ì´ë¦„: {in_name}")
                print("ğŸ” ë””ì½”ë” after resolve:")
                for d in decoders_resolved:
                    print(f"    stride={d['stride']}, reg={d['reg_layer']}, cls={d['cls_layer']}")

                # ì¹´ë©”ë¼ ì—´ê¸°
                cap = open_capture(args)
                if not cap.isOpened():
                    print("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨")
                    sys.exit(1)

                # MJPEG ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ /video ì œê³µ)
                http_thread = start_mjpeg_server(host="0.0.0.0", port=5055)

                # ë¡œì»¬ ì°½ ì˜µì…˜ ì²˜ë¦¬ (ê¸°ë³¸ headless: ì°½ X)
                if args.window:
                    cv2.namedWindow("ğŸ”¥ Hailo YOLOv8 Detection (MQTT)", cv2.WINDOW_NORMAL)
                    cv2.resizeWindow("ğŸ”¥ Hailo YOLOv8 Detection (MQTT)", 960, 540)
                    print("ğŸ“¸ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘ â€” 'q' ëˆ„ë¥´ë©´ ì¢…ë£Œ (ìœˆë„ìš° ëª¨ë“œ)")
                else:
                    print("ğŸ“¸ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ)")

                printed_probe = False

                while not stop_event.is_set():
                    loop_start = time.time()

                    # 1) í”„ë ˆì„ ìº¡ì²˜
                    t0 = time.time()
                    ret, frame_bgr = cap.read()
                    t1 = time.time()
                    if not ret or frame_bgr is None:
                        print("â— í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                        break

                    if not printed_probe:
                        try:
                            print(f"[PROBE] ret={ret}, shape={frame_bgr.shape}, mean={float(frame_bgr.mean()):.2f}")
                        except Exception:
                            print(f"[PROBE] ret={ret}, frame=None")
                        printed_probe = True

                    orig_h, orig_w = frame_bgr.shape[:2]

                    # 2) ì „ì²˜ë¦¬ â†’ RGB uint8 (net_h x net_w)
                    t2_prep_start = time.time()
                    img_rgb_crop, scale, left, top = preprocess_for_hailo(
                        frame_bgr,
                        net_h=net_h,
                        net_w=net_w
                    )
                    t2 = time.time()

                    # 3) Hailo ì¶”ë¡ 
                    t3_infer_start = time.time()

                    # HailoëŠ” (ë°°ì¹˜, H, W, C) = (1,640,640,3) uint8, NHWCë¥¼ ê¸°ëŒ€
                    hailo_input = np.expand_dims(img_rgb_crop, axis=0).astype(np.uint8, copy=False)
                    hailo_input = np.ascontiguousarray(hailo_input)

                    # ë””ë²„ê·¸
                    print("[DEBUG] hailo_input shape:", hailo_input.shape)
                    print("[DEBUG] hailo_input dtype:", hailo_input.dtype)
                    print("[DEBUG] hailo_input nbytes:", hailo_input.nbytes)
                    print("[DEBUG] hailo_input C_CONTIGUOUS?:", hailo_input.flags['C_CONTIGUOUS'])

                    # ì‹¤ì œ ì¶”ë¡ 
                    results = infer_pipeline.infer({in_name: hailo_input})
                    t3 = time.time()

                    # 4) í›„ì²˜ë¦¬ (DFL decode + NMS)
                    t4_post_start = time.time()
                    det = postprocess_all_scales(
                        results_dict=results,
                        decoders_resolved=decoders_resolved,
                        num_bins=cfg_num_bins,
                        score_thr=score_thr,
                        iou_th=iou_thr,
                        max_det=max_det
                    )
                    t4 = time.time()

                    # 5) ë°•ìŠ¤ ê·¸ë¦¬ê¸° & MQTT
                    t5_draw_start = time.time()
                    if det is not None and det.size > 0:
                        # det: [x1,y1,x2,y2,score,cls_id] ëª¨ë¸ ì¢Œí‘œ(640x640 crop)
                        for (x1m, y1m, x2m, y2m, conf, cls_id) in det:
                            # ëª¨ë¸ ì¢Œí‘œ -> ì›ë³¸ frame ì¢Œí‘œ
                            x1_px, y1_px, x2_px, y2_px = map_box_back_to_original(
                                x1m, y1m, x2m, y2m,
                                scale, left, top,
                                orig_w, orig_h
                            )

                            # í•­ìƒ ì¢Œí‘œë¥¼ (ì™¼ìª½ìœ„, ì˜¤ë¥¸ìª½ì•„ë˜) ìˆœì„œë¡œ ì •ë ¬
                            x1_draw = int(min(x1_px, x2_px))
                            y1_draw = int(min(y1_px, y2_px))
                            x2_draw = int(max(x1_px, x2_px))
                            y2_draw = int(max(y1_px, y2_px))

                            # ë¼ë²¨ ê²°ì •
                            if labels and 0 <= int(cls_id) < len(labels):
                                label_str = labels[int(cls_id)]
                            else:
                                label_str = f"id:{int(cls_id)}"

                            # ë””ë²„ê·¸ ì¶œë ¥
                            print(
                                f"[BOX] {label_str} conf={conf:.2f} "
                                f"box=({x1_draw},{y1_draw})-({x2_draw},{y2_draw}) "
                                f"frame_size={orig_w}x{orig_h}"
                            )

                            cv2.rectangle(
                                frame_bgr,
                                (x1_draw, y1_draw),
                                (x2_draw, y2_draw),
                                (0, 0, 255),
                                4
                            )

                            cx = int((x1_draw + x2_draw) / 2)
                            cy = int((y1_draw + y2_draw) / 2)
                            cv2.circle(frame_bgr, (cx, cy), 5, (0, 255, 0), -1)

                            cv2.putText(
                                frame_bgr,
                                f"{label_str} {conf:.2f}",
                                (x1_draw, max(y1_draw - 8, 10)),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                0.7,
                                (0, 0, 255),
                                2
                            )

                            # fire / smoke ê°ì§€ ì‹œ MQTT ì „ì†¡
                            low_label = str(label_str).lower().strip()
                            if low_label in ("fire", "smoke"):
                                mqtt_client = send_detection_mqtt(mqtt_client, low_label)

                    # FPS í‘œì‹œ
                    loop_end_now = time.time()
                    fps_display = 1.0 / max(1e-6, (loop_end_now - loop_start))
                    cv2.putText(
                        frame_bgr,
                        f"FPS: {fps_display:.2f}",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.8,
                        (0, 255, 0),
                        2
                    )

                    # ğŸ”¥ MJPEGìš© ìµœì‹  í”„ë ˆì„ ì—…ë°ì´íŠ¸
                    ok, jpeg_buf = cv2.imencode(".jpg", frame_bgr)
                    if ok:
                        latest_jpeg = jpeg_buf.tobytes()

                    # ë¡œì»¬ ë¯¸ë¦¬ë³´ê¸° ì°½ (ì›í•˜ë©´ë§Œ)
                    if args.window:
                        cv2.imshow("ğŸ”¥ Hailo YOLOv8 Detection (MQTT)", frame_bgr)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            _request_shutdown("user pressed q")

                    t5 = time.time()

                    # 6) íƒ€ì´ë° ë””ë²„ê·¸
                    print(
                        "â± ì„±ëŠ¥ì¸¡ì • | "
                        f"ìº¡ì²˜ {(t1 - t0)*1000:.1f}ms | "
                        f"ì „ì²˜ë¦¬ {(t2 - t2_prep_start)*1000:.1f}ms | "
                        f"Hailo {(t3 - t3_infer_start)*1000:.1f}ms | "
                        f"í›„ì²˜ë¦¬ {(t4 - t4_post_start)*1000:.1f}ms | "
                        f"í‘œì‹œ/ì „ì†¡ {(t5 - t5_draw_start)*1000:.1f}ms | "
                        f"ì „ì²´ {(t5 - t0)*1000:.1f}ms | "
                        f"FPS {fps_display:.2f}"
                    )

                # ì •ë¦¬
                cap.release()
                if args.window:
                    cv2.destroyAllWindows()

    # MQTT ë©”ì¸ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
    if mqtt_client:
        try:
            mqtt_client.loop_stop()
            mqtt_client.disconnect()
        except Exception:
            pass

    # ì˜¨ë„ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° (ìµœëŒ€ 2ì´ˆ)
    temp_thread.join(timeout=2)
    print("âœ… ë©”ì¸ ì¢…ë£Œ ì™„ë£Œ")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¸ì íŒŒì„œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_args():
    p = argparse.ArgumentParser()

    # Hailo ëª¨ë¸ / ë¼ë²¨ / í›„ì²˜ë¦¬ config
    p.add_argument("--hef-path", type=str, default="./fire.hef",
                   help="compile.pyì—ì„œ ë½‘ì€ HEF ê²½ë¡œ")
    p.add_argument("--labels-path", type=str, default="./labels.json",
                   help='{"labels":["fire","smoke",...]} ì´ëŸ° êµ¬ì¡°')
    p.add_argument("--config-path", type=str,
                   default="/home/dlgyals/Downloads/hailo/models/yolov8n_nms_config.json",
                   help="yolov8n_nms_config.json ê²½ë¡œ")

    # ì¹´ë©”ë¼
    p.add_argument("--camera-index", type=int, default=0)
    p.add_argument("--api", choices=["auto", "v4l2", "gst"], default="v4l2",
                   help="ì¹´ë©”ë¼ ë°±ì—”ë“œ (ë¼ì¦ˆíŒŒì´ëŠ” v4l2 ê¶Œì¥)")
    p.add_argument("--fourcc", choices=["MJPG", "YUYV", "NONE"], default="MJPG",
                   help="ì¹´ë©”ë¼ í¬ë§· (USBìº ì€ MJPGê°€ ê³ FPS ì˜ ë‚˜ì˜´)")
    p.add_argument("--cap-width", type=int, default=640,
                   help="ì¹´ë©”ë¼ ìš”ì²­ ê°€ë¡œ í•´ìƒë„")
    p.add_argument("--cap-height", type=int, default=640,
                   help="ì¹´ë©”ë¼ ìš”ì²­ ì„¸ë¡œ í•´ìƒë„")

    # í›„ì²˜ë¦¬ threshold / NMS
    p.add_argument("--score-thr", type=float, default=None,
                   help="ë°•ìŠ¤ë¡œ ì¸ì •í•  ìµœì†Œ confidence (ê¸°ë³¸ì€ json nms_scores_th)")
    p.add_argument("--iou-thr", type=float, default=None,
                   help="NMS IoU ì„ê³„ê°’ (ê¸°ë³¸ì€ json nms_iou_th)")
    p.add_argument("--max-det", type=int, default=None,
                   help="ìµœì¢… NMS í›„ ë‚¨ê¸¸ ìµœëŒ€ ë°•ìŠ¤ ìˆ˜ (ê¸°ë³¸ì€ json max_proposals_per_class)")

    # â–¶ï¸ í—¤ë“œë¦¬ìŠ¤/ìœˆë„ìš° ëª¨ë“œ ìŠ¤ìœ„ì¹˜
    p.add_argument("--window", action="store_true",
                   help="ë¡œì»¬ ë¯¸ë¦¬ë³´ê¸° ì°½ì„ ë„ì›€(ê¸°ë³¸: í—¤ë“œë¦¬ìŠ¤)")

    return p.parse_args()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ë¶€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    _setup_signal_handlers()
    try:
        args = parse_args()
        main(args)
    except KeyboardInterrupt:
        _request_shutdown("KeyboardInterrupt")
    except Exception as e:
        print("âŒ ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        sys.exit(1)
    finally:
        # í˜¹ì‹œ ë‚¨ì•„ìˆìœ¼ë©´ í•œ ë²ˆ ë” ì¢…ë£Œ ì‹ í˜¸
        stop_event.set()
        print("ğŸ‘‹ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        sys.exit(0)
